{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gp/vqql8_v1253_d8bwfqk_0gb40000gn/T/ipykernel_3849/2693103964.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import permutations\n",
    "import math\n",
    "import os\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cargo_capacity_psv = 100\n",
    "psv_speed = 10\n",
    "max_platforms_in_one_voyage = 7\n",
    "\n",
    "mappenavn = 'generated_datafiles_allroutes16'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reads input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = pd.read_csv('clustering/output_platforms_demand.csv', header=0, delimiter=';')\n",
    "distances = pd.read_csv('clustering/output_distance_matrix_kmeans.csv', header=0, delimiter=';', index_col='from/to')\n",
    "\n",
    "platforms_demand = dict(zip(demand['platform'], demand['avg_q'].replace(',', '.').astype(float)))\n",
    "platforms_d = ['MON'] + demand['platform'].tolist() + ['MON']  # Add 'DUS' as start and end platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm for generating the shortest routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Keep track of dominated routes to skip future routes starting with them\u001b[39;00m\n\u001b[1;32m     60\u001b[0m dominated_routes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m---> 61\u001b[0m shortest_routes_dict \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_routes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m route, distance, demand, duration_sailing, duration_lossing \u001b[38;5;129;01min\u001b[39;00m shortest_routes_dict\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShortest Route: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroute\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Total Distance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(distance,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Total Demand: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdemand\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Duration sailing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration_sailing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Duration lossing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration_lossing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 52\u001b[0m, in \u001b[0;36mgenerate_routes\u001b[0;34m(demand, distances)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m route_combination \u001b[38;5;129;01min\u001b[39;00m permutations(platforms_demand\u001b[38;5;241m.\u001b[39mkeys(), r \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     51\u001b[0m     route \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMON\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(route_combination) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMON\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 52\u001b[0m     \u001b[43mdp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMON\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcargo_capacity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMON\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Add the current route to the dominated routes set\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     dominated_routes\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mtuple\u001b[39m(route))\n",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m, in \u001b[0;36mgenerate_routes.<locals>.dp\u001b[0;34m(platform, cargo_remaining, route, visited)\u001b[0m\n\u001b[1;32m      4\u001b[0m cargo_capacity \u001b[38;5;241m=\u001b[39m cargo_capacity_psv\n\u001b[1;32m      5\u001b[0m max_platforms \u001b[38;5;241m=\u001b[39m max_platforms_in_one_voyage \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdp\u001b[39m(platform, cargo_remaining, route, visited):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cargo_remaining \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shortest_routes_dict = {}\n",
    "\n",
    "def generate_routes(demand, distances):\n",
    "    cargo_capacity = cargo_capacity_psv\n",
    "    max_platforms = max_platforms_in_one_voyage + 2\n",
    "\n",
    "    def dp(platform, cargo_remaining, route, visited):\n",
    "        if cargo_remaining < 0:\n",
    "            return\n",
    "        if len(route) > max_platforms:\n",
    "            return\n",
    "        if platform == 'MON' and len(route) > 2:\n",
    "            total_demand = sum(platforms_demand[p] for p in route[1:-1])\n",
    "            if total_demand <= cargo_capacity:\n",
    "                key = tuple(sorted(set(route)))\n",
    "                total_distance = sum(distances.loc[route[i], route[i+1]] for i in range(len(route)-1))\n",
    "                if key not in shortest_routes_dict or total_distance < shortest_routes_dict[key][1]:\n",
    "                    duration_sailing = round((total_distance / psv_speed), 2)\n",
    "                    duration_lossing = round(((total_demand * 1.389) / psv_speed), 2)\n",
    "                    duration_sailing = round(duration_sailing, 2)\n",
    "                    duration_lossing = round(duration_lossing, 2)\n",
    "                    shortest_routes_dict[key] = (route, total_distance, total_demand, duration_sailing, duration_lossing)\n",
    "            return\n",
    "\n",
    "        # Check if the current route is dominated\n",
    "        current_distance = sum(distances.loc[route[i], route[i+1]] for i in range(len(route)-1))\n",
    "        current_demand = sum(platforms_demand[p] for p in route[1:-1])\n",
    "        \n",
    "        # Check for dominance in existing routes\n",
    "        for key, (existing_route, existing_distance, existing_demand, _, _) in shortest_routes_dict.items():\n",
    "            if set(existing_route[1:-1]) == set(route[1:-1]) and existing_demand >= current_demand and existing_distance <= current_distance:\n",
    "                return\n",
    "        \n",
    "        # Check for dominance in subsequent routes starting with the same platforms\n",
    "        for existing_route in dominated_routes:\n",
    "            if set(existing_route[1:-1]) == set(route[1:-1]) and existing_demand >= current_demand and existing_distance <= current_distance:\n",
    "                return\n",
    "\n",
    "        for next_platform in platforms_demand.keys():\n",
    "            if next_platform != platform and next_platform not in visited:\n",
    "                try:\n",
    "                    distance_to_next = distances.loc[platform, next_platform]\n",
    "                    new_cargo_remaining = cargo_remaining - platforms_demand[next_platform]\n",
    "                    dp(next_platform, new_cargo_remaining, route + [next_platform], visited.union({next_platform}))\n",
    "                except KeyError:\n",
    "                    print(\"KeyError occurred for platform:\", next_platform)\n",
    "                    continue\n",
    "\n",
    "    for r in range(3, min(len(platforms_demand) + 3, max_platforms + 3)):\n",
    "        for route_combination in permutations(platforms_demand.keys(), r - 2):\n",
    "            route = ['MON'] + list(route_combination) + ['MON']\n",
    "            dp('MON', cargo_capacity, route, {'MON'})\n",
    "\n",
    "            # Add the current route to the dominated routes set\n",
    "            dominated_routes.add(tuple(route))\n",
    "\n",
    "    return shortest_routes_dict\n",
    "\n",
    "# Keep track of dominated routes to skip future routes starting with them\n",
    "dominated_routes = set()\n",
    "shortest_routes_dict = generate_routes(demand, distances)\n",
    "\n",
    "for route, distance, demand, duration_sailing, duration_lossing in shortest_routes_dict.values():\n",
    "    print(f\"Shortest Route: {route}, Total Distance: {round(distance,2)}, Total Demand: {demand}, Duration sailing: {duration_sailing}, Duration lossing: {duration_lossing}\")\n",
    "\n",
    "print(len(shortest_routes_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saves the shortest routes left to csv files in the generated_datafiles folder. In total 858 routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_only = [route for route, _, _, _, _ in shortest_routes_dict.values()]\n",
    "distances_only = [distance for _, distance, _, _, _ in shortest_routes_dict.values()]\n",
    "demand_only = [demand for _, _, demand, _, _ in shortest_routes_dict.values()]\n",
    "duration_sailing = [duration_sailing for _, _, _, duration_sailing, _ in shortest_routes_dict.values()]\n",
    "duration_lossing = [duration_lossing for _, _, _, _, duration_lossing in shortest_routes_dict.values()]\n",
    "\n",
    "df_distances = pd.DataFrame({'Distance': distances_only})\n",
    "df_demand = pd.DataFrame({'Demand': demand_only})\n",
    "df_duration_sailing = pd.DataFrame({'Duration (hours)': duration_sailing})\n",
    "df_duration_lossing = pd.DataFrame({'Duration (hours)': duration_lossing})\n",
    "\n",
    "df_distances.to_csv(f'{mappenavn}/distances.csv', index=False)\n",
    "df_demand.to_csv(f'{mappenavn}/demand.csv', index=False)\n",
    "df_duration_sailing.to_csv(f'{mappenavn}/duration_sailing.csv', index=False)\n",
    "df_duration_lossing.to_csv(f'{mappenavn}/duration_lossing.csv', index=False)\n",
    "route_file = f'{mappenavn}/routes.csv'\n",
    "\n",
    "\n",
    "def write_to_csv(filename, data):\n",
    "    with open(filename, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(data)\n",
    "\n",
    "write_to_csv(route_file, routes_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the reduced set of routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport csv\\n\\ndef contains_required_routes(route, required_routes):\\n    return all(required_route in route for required_route in required_routes)\\n\\ndef main():\\n    hda_additional_routes1 = [\"HDA\", \"SLB\"]\\n    hda_additional_routes2 = [\"HDA\", \"SLA\"]\\n    hda_additional_routes3 = [\"HDA\", \"DRA\"]\\n    hda_additional_routes4 = [\"HDA\", \"TEB\"]\\n    \\n    dra_additional_routes1 = [\"DRA\", \"DAB\"]\\n    dra_additional_routes2 = [\"DRA\", \"GRA\"]\\n\\n    gkr_additional_routes1 = [\"GKR\", \"HDA\"]\\n\\n    teb_additional_routes1 = [\"TEB\", \"DAB\"]\\n    teb_additional_routes2 = [\"TEB\", \"GRA\"]\\n\\n    sla_additional_routes1 = [\"SLA\", \"DAB\"]\\n    sla_additional_routes2 = [\"SLA\", \"GRA\"]\\n\\n    slb_additional_routes1 = [\"SLB\", \"DAB\"]\\n    slb_additional_routes2 = [\"SLB\", \"GRA\"]\\n\\n    routes_with_hda_slb = []\\n    routes_with_hda_sla = []\\n    routes_with_hda_dra = []\\n    routes_with_hda_teb = []\\n\\n    routes_with_dra_dab = []\\n    routes_with_dra_gra = []\\n    routes_with_gkr_hda = []\\n    routes_with_teb_dab = []\\n\\n    routes_with_teb_gra = []\\n    routes_with_sla_dab = []\\n    routes_with_sla_gra = []\\n    routes_with_slb_dab = []\\n    routes_with_slb_gra = []\\n\\n    with open(\\'generated_datafiles_allroutes/routes.csv\\', \\'r\\') as file:\\n        csv_reader = csv.reader(file)\\n        for row_number, row in enumerate(csv_reader, start=1):\\n            if contains_required_routes(row, hda_additional_routes1):\\n                routes_with_hda_slb.append(row_number)\\n            if contains_required_routes(row, hda_additional_routes2):\\n                routes_with_hda_sla.append(row_number)\\n            if contains_required_routes(row, hda_additional_routes3):\\n                routes_with_hda_dra.append(row_number)\\n            if contains_required_routes(row, hda_additional_routes4):\\n                routes_with_hda_teb.append(row_number)\\n            if contains_required_routes(row, dra_additional_routes1):\\n                routes_with_dra_dab.append(row_number)\\n            if contains_required_routes(row, dra_additional_routes2):\\n                routes_with_dra_gra.append(row_number)\\n\\n            if contains_required_routes(row, gkr_additional_routes1):\\n                routes_with_gkr_hda.append(row_number)\\n\\n            if contains_required_routes(row, teb_additional_routes1):\\n                routes_with_teb_dab.append(row_number)\\n            if contains_required_routes(row, teb_additional_routes2):\\n                routes_with_teb_gra.append(row_number)\\n            if contains_required_routes(row, sla_additional_routes1):\\n                routes_with_sla_dab.append(row_number)\\n            if contains_required_routes(row, sla_additional_routes2):\\n                routes_with_sla_gra.append(row_number)\\n            if contains_required_routes(row, slb_additional_routes1):\\n                routes_with_slb_dab.append(row_number)\\n            if contains_required_routes(row, slb_additional_routes2):\\n                routes_with_slb_gra.append(row_number)\\n            \\n    # Finding rows where all combinations occur\\n    # Combine all lists into one\\n    all_routes = (\\n        routes_with_hda_slb + \\n        routes_with_hda_sla +\\n        routes_with_hda_dra +\\n        routes_with_hda_teb +\\n        routes_with_dra_dab +\\n        routes_with_dra_gra +\\n        routes_with_gkr_hda +\\n        routes_with_teb_dab +\\n        routes_with_teb_gra +\\n        routes_with_sla_dab +\\n        routes_with_sla_gra +\\n        routes_with_slb_dab +\\n        routes_with_slb_gra\\n    )\\n    \\n    # Convert the combined list into a set to remove duplicates\\n    unique_routes = set(all_routes)\\n\\n    # Convert the set back into a list if needed\\n    unique_routes_list = list(unique_routes)\\n    print((sorted(unique_routes_list)))\\n    print(len(unique_routes_list))\\n\\n    def filter_routes(input_file, output_file, exclude_indices):\\n        with open(input_file, \\'r\\', newline=\\'\\') as f_in,             open(output_file, \\'w\\', newline=\\'\\') as f_out:\\n            reader = csv.reader(f_in)\\n            writer = csv.writer(f_out)\\n\\n            for i, row in enumerate(reader):\\n                if i + 1 not in exclude_indices:  # Adjusting for 1-based indexing\\n                    writer.writerow(row)\\n\\n    def filter_otherfiles(input_file, output_file, exclude_indices):\\n        with open(input_file, \\'r\\', newline=\\'\\') as f_in,             open(output_file, \\'w\\', newline=\\'\\') as f_out:\\n            reader = csv.reader(f_in)\\n            writer = csv.writer(f_out)\\n\\n            for i, row in enumerate(reader):\\n                if i not in exclude_indices:  \\n                    writer.writerow(row)\\n\\n    # Example usage\\n    input_file = \\'generated_datafiles_allroutes/routes.csv\\'\\n    output_file = \\'generated_datafiles_reducedroutes/routes.csv\\'\\n\\n    input_file2 = \\'generated_datafiles_allroutes/demand.csv\\'\\n    output_file2 = \\'generated_datafiles_reducedroutes/demand.csv\\'\\n\\n    input_file3 = \\'generated_datafiles_allroutes/distances.csv\\'\\n    output_file3 = \\'generated_datafiles_reducedroutes/distances.csv\\'\\n\\n    input_file4 = \\'generated_datafiles_allroutes/duration_lossing.csv\\'\\n    output_file4 = \\'generated_datafiles_reducedroutes/duration_lossing.csv\\'\\n\\n    input_file5 = \\'generated_datafiles_allroutes/duration_sailing.csv\\'\\n    output_file5 = \\'generated_datafiles_reducedroutes/duration_sailing.csv\\'\\n\\n    filter_routes(input_file, output_file, unique_routes_list)\\n    filter_otherfiles(input_file2, output_file2, unique_routes_list)\\n    filter_otherfiles(input_file3, output_file3, unique_routes_list)\\n    filter_otherfiles(input_file4, output_file4, unique_routes_list)\\n    filter_otherfiles(input_file5, output_file5, unique_routes_list)\\n\\nif __name__ == \"__main__\":\\n    main()\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import csv\n",
    "\n",
    "def contains_required_routes(route, required_routes):\n",
    "    return all(required_route in route for required_route in required_routes)\n",
    "\n",
    "def main():\n",
    "    hda_additional_routes1 = [\"HDA\", \"SLB\"]\n",
    "    hda_additional_routes2 = [\"HDA\", \"SLA\"]\n",
    "    hda_additional_routes3 = [\"HDA\", \"DRA\"]\n",
    "    hda_additional_routes4 = [\"HDA\", \"TEB\"]\n",
    "    \n",
    "    dra_additional_routes1 = [\"DRA\", \"DAB\"]\n",
    "    dra_additional_routes2 = [\"DRA\", \"GRA\"]\n",
    "\n",
    "    gkr_additional_routes1 = [\"GKR\", \"HDA\"]\n",
    "\n",
    "    teb_additional_routes1 = [\"TEB\", \"DAB\"]\n",
    "    teb_additional_routes2 = [\"TEB\", \"GRA\"]\n",
    "\n",
    "    sla_additional_routes1 = [\"SLA\", \"DAB\"]\n",
    "    sla_additional_routes2 = [\"SLA\", \"GRA\"]\n",
    "\n",
    "    slb_additional_routes1 = [\"SLB\", \"DAB\"]\n",
    "    slb_additional_routes2 = [\"SLB\", \"GRA\"]\n",
    "\n",
    "    routes_with_hda_slb = []\n",
    "    routes_with_hda_sla = []\n",
    "    routes_with_hda_dra = []\n",
    "    routes_with_hda_teb = []\n",
    "\n",
    "    routes_with_dra_dab = []\n",
    "    routes_with_dra_gra = []\n",
    "    routes_with_gkr_hda = []\n",
    "    routes_with_teb_dab = []\n",
    "\n",
    "    routes_with_teb_gra = []\n",
    "    routes_with_sla_dab = []\n",
    "    routes_with_sla_gra = []\n",
    "    routes_with_slb_dab = []\n",
    "    routes_with_slb_gra = []\n",
    "\n",
    "    with open('generated_datafiles_allroutes/routes.csv', 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for row_number, row in enumerate(csv_reader, start=1):\n",
    "            if contains_required_routes(row, hda_additional_routes1):\n",
    "                routes_with_hda_slb.append(row_number)\n",
    "            if contains_required_routes(row, hda_additional_routes2):\n",
    "                routes_with_hda_sla.append(row_number)\n",
    "            if contains_required_routes(row, hda_additional_routes3):\n",
    "                routes_with_hda_dra.append(row_number)\n",
    "            if contains_required_routes(row, hda_additional_routes4):\n",
    "                routes_with_hda_teb.append(row_number)\n",
    "            if contains_required_routes(row, dra_additional_routes1):\n",
    "                routes_with_dra_dab.append(row_number)\n",
    "            if contains_required_routes(row, dra_additional_routes2):\n",
    "                routes_with_dra_gra.append(row_number)\n",
    "\n",
    "            if contains_required_routes(row, gkr_additional_routes1):\n",
    "                routes_with_gkr_hda.append(row_number)\n",
    "\n",
    "            if contains_required_routes(row, teb_additional_routes1):\n",
    "                routes_with_teb_dab.append(row_number)\n",
    "            if contains_required_routes(row, teb_additional_routes2):\n",
    "                routes_with_teb_gra.append(row_number)\n",
    "            if contains_required_routes(row, sla_additional_routes1):\n",
    "                routes_with_sla_dab.append(row_number)\n",
    "            if contains_required_routes(row, sla_additional_routes2):\n",
    "                routes_with_sla_gra.append(row_number)\n",
    "            if contains_required_routes(row, slb_additional_routes1):\n",
    "                routes_with_slb_dab.append(row_number)\n",
    "            if contains_required_routes(row, slb_additional_routes2):\n",
    "                routes_with_slb_gra.append(row_number)\n",
    "            \n",
    "    # Finding rows where all combinations occur\n",
    "    # Combine all lists into one\n",
    "    all_routes = (\n",
    "        routes_with_hda_slb + \n",
    "        routes_with_hda_sla +\n",
    "        routes_with_hda_dra +\n",
    "        routes_with_hda_teb +\n",
    "        routes_with_dra_dab +\n",
    "        routes_with_dra_gra +\n",
    "        routes_with_gkr_hda +\n",
    "        routes_with_teb_dab +\n",
    "        routes_with_teb_gra +\n",
    "        routes_with_sla_dab +\n",
    "        routes_with_sla_gra +\n",
    "        routes_with_slb_dab +\n",
    "        routes_with_slb_gra\n",
    "    )\n",
    "    \n",
    "    # Convert the combined list into a set to remove duplicates\n",
    "    unique_routes = set(all_routes)\n",
    "\n",
    "    # Convert the set back into a list if needed\n",
    "    unique_routes_list = list(unique_routes)\n",
    "    print((sorted(unique_routes_list)))\n",
    "    print(len(unique_routes_list))\n",
    "\n",
    "    def filter_routes(input_file, output_file, exclude_indices):\n",
    "        with open(input_file, 'r', newline='') as f_in, \\\n",
    "            open(output_file, 'w', newline='') as f_out:\n",
    "            reader = csv.reader(f_in)\n",
    "            writer = csv.writer(f_out)\n",
    "\n",
    "            for i, row in enumerate(reader):\n",
    "                if i + 1 not in exclude_indices:  # Adjusting for 1-based indexing\n",
    "                    writer.writerow(row)\n",
    "\n",
    "    def filter_otherfiles(input_file, output_file, exclude_indices):\n",
    "        with open(input_file, 'r', newline='') as f_in, \\\n",
    "            open(output_file, 'w', newline='') as f_out:\n",
    "            reader = csv.reader(f_in)\n",
    "            writer = csv.writer(f_out)\n",
    "\n",
    "            for i, row in enumerate(reader):\n",
    "                if i not in exclude_indices:  \n",
    "                    writer.writerow(row)\n",
    "\n",
    "    # Example usage\n",
    "    input_file = 'generated_datafiles_allroutes/routes.csv'\n",
    "    output_file = 'generated_datafiles_reducedroutes/routes.csv'\n",
    "\n",
    "    input_file2 = 'generated_datafiles_allroutes/demand.csv'\n",
    "    output_file2 = 'generated_datafiles_reducedroutes/demand.csv'\n",
    "\n",
    "    input_file3 = 'generated_datafiles_allroutes/distances.csv'\n",
    "    output_file3 = 'generated_datafiles_reducedroutes/distances.csv'\n",
    "\n",
    "    input_file4 = 'generated_datafiles_allroutes/duration_lossing.csv'\n",
    "    output_file4 = 'generated_datafiles_reducedroutes/duration_lossing.csv'\n",
    "\n",
    "    input_file5 = 'generated_datafiles_allroutes/duration_sailing.csv'\n",
    "    output_file5 = 'generated_datafiles_reducedroutes/duration_sailing.csv'\n",
    "\n",
    "    filter_routes(input_file, output_file, unique_routes_list)\n",
    "    filter_otherfiles(input_file2, output_file2, unique_routes_list)\n",
    "    filter_otherfiles(input_file3, output_file3, unique_routes_list)\n",
    "    filter_otherfiles(input_file4, output_file4, unique_routes_list)\n",
    "    filter_otherfiles(input_file5, output_file5, unique_routes_list)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

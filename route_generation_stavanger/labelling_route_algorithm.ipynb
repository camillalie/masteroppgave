{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gp/vqql8_v1253_d8bwfqk_0gb40000gn/T/ipykernel_4986/158659454.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import math\n",
    "import os\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cargo_capacity_psv = 100\n",
    "psv_speed = 7 #7 for strøm, 10 på resten\n",
    "max_platforms_in_one_voyage = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reads input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = pd.read_csv('clustering/output_platforms_demand.csv', header=0, delimiter=';')\n",
    "distances = pd.read_csv('clustering/output_distance_matrix_kmeans.csv', header=0, delimiter=';', index_col='from/to')\n",
    "\n",
    "platforms_demand = dict(zip(demand['platform'], demand['avg_q'].replace(',', '.').astype(float)))\n",
    "platforms_d = ['DUS'] + demand['platform'].tolist() + ['DUS']  # Add 'DUS' as start and end platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm for generating the shortest routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest Route: ['DUS', 'DABGRAHDA', 'DUS'], Total Distance: 235.0, Total Demand: 68.5, Duration sailing: 33.57, Duration lossing: 13.59\n",
      "Shortest Route: ['DUS', 'DRA', 'DUS'], Total Distance: 205.36, Total Demand: 14.0, Duration sailing: 29.34, Duration lossing: 2.78\n",
      "Shortest Route: ['DUS', 'DSAJSF', 'DUS'], Total Distance: 183.8, Total Demand: 61.75, Duration sailing: 26.26, Duration lossing: 12.25\n",
      "Shortest Route: ['DUS', 'GKRSLASLB', 'DUS'], Total Distance: 246.84, Total Demand: 18.0, Duration sailing: 35.26, Duration lossing: 3.57\n",
      "Shortest Route: ['DUS', 'GUD', 'DUS'], Total Distance: 226.76, Total Demand: 18.0, Duration sailing: 32.39, Duration lossing: 3.57\n",
      "Shortest Route: ['DUS', 'TEB', 'DUS'], Total Distance: 250.32, Total Demand: 14.0, Duration sailing: 35.76, Duration lossing: 2.78\n",
      "Shortest Route: ['DUS', 'DABGRAHDA', 'DRA', 'DUS'], Total Distance: 309.07, Total Demand: 82.5, Duration sailing: 44.15, Duration lossing: 16.37\n",
      "Shortest Route: ['DUS', 'DABGRAHDA', 'GKRSLASLB', 'DUS'], Total Distance: 323.73, Total Demand: 86.5, Duration sailing: 46.25, Duration lossing: 17.16\n",
      "Shortest Route: ['DUS', 'DABGRAHDA', 'GUD', 'DUS'], Total Distance: 286.48, Total Demand: 86.5, Duration sailing: 40.93, Duration lossing: 17.16\n",
      "Shortest Route: ['DUS', 'DABGRAHDA', 'TEB', 'DUS'], Total Distance: 326.3, Total Demand: 82.5, Duration sailing: 46.61, Duration lossing: 16.37\n",
      "Shortest Route: ['DUS', 'DRA', 'DSAJSF', 'DUS'], Total Distance: 238.8, Total Demand: 75.75, Duration sailing: 34.11, Duration lossing: 15.03\n",
      "Shortest Route: ['DUS', 'DRA', 'GKRSLASLB', 'DUS'], Total Distance: 259.63, Total Demand: 32.0, Duration sailing: 37.09, Duration lossing: 6.35\n",
      "Shortest Route: ['DUS', 'DRA', 'GUD', 'DUS'], Total Distance: 261.82, Total Demand: 32.0, Duration sailing: 37.4, Duration lossing: 6.35\n",
      "Shortest Route: ['DUS', 'DRA', 'TEB', 'DUS'], Total Distance: 258.83, Total Demand: 28.0, Duration sailing: 36.98, Duration lossing: 5.56\n",
      "Shortest Route: ['DUS', 'DSAJSF', 'GKRSLASLB', 'DUS'], Total Distance: 263.54, Total Demand: 79.75, Duration sailing: 37.65, Duration lossing: 15.82\n",
      "Shortest Route: ['DUS', 'DSAJSF', 'GUD', 'DUS'], Total Distance: 240.94, Total Demand: 79.75, Duration sailing: 34.42, Duration lossing: 15.82\n",
      "Shortest Route: ['DUS', 'DSAJSF', 'TEB', 'DUS'], Total Distance: 267.43, Total Demand: 75.75, Duration sailing: 38.2, Duration lossing: 15.03\n",
      "Shortest Route: ['DUS', 'GKRSLASLB', 'GUD', 'DUS'], Total Distance: 267.11, Total Demand: 36.0, Duration sailing: 38.16, Duration lossing: 7.14\n",
      "Shortest Route: ['DUS', 'GKRSLASLB', 'TEB', 'DUS'], Total Distance: 263.67, Total Demand: 32.0, Duration sailing: 37.67, Duration lossing: 6.35\n",
      "Shortest Route: ['DUS', 'GUD', 'TEB', 'DUS'], Total Distance: 267.97, Total Demand: 32.0, Duration sailing: 38.28, Duration lossing: 6.35\n",
      "Shortest Route: ['DUS', 'DABGRAHDA', 'DRA', 'TEB', 'DUS'], Total Distance: 362.54, Total Demand: 96.5, Duration sailing: 51.79, Duration lossing: 19.15\n",
      "Shortest Route: ['DUS', 'DRA', 'DSAJSF', 'GKRSLASLB', 'DUS'], Total Distance: 318.54, Total Demand: 93.75, Duration sailing: 45.51, Duration lossing: 18.6\n",
      "Shortest Route: ['DUS', 'DRA', 'DSAJSF', 'GUD', 'DUS'], Total Distance: 295.94, Total Demand: 93.75, Duration sailing: 42.28, Duration lossing: 18.6\n",
      "Shortest Route: ['DUS', 'DRA', 'DSAJSF', 'TEB', 'DUS'], Total Distance: 322.43, Total Demand: 89.75, Duration sailing: 46.06, Duration lossing: 17.81\n",
      "Shortest Route: ['DUS', 'DRA', 'GKRSLASLB', 'GUD', 'DUS'], Total Distance: 279.9, Total Demand: 50.0, Duration sailing: 39.99, Duration lossing: 9.92\n",
      "Shortest Route: ['DUS', 'DRA', 'GKRSLASLB', 'TEB', 'DUS'], Total Distance: 276.46, Total Demand: 46.0, Duration sailing: 39.49, Duration lossing: 9.13\n",
      "Shortest Route: ['DUS', 'DRA', 'GUD', 'TEB', 'DUS'], Total Distance: 303.03, Total Demand: 46.0, Duration sailing: 43.29, Duration lossing: 9.13\n",
      "Shortest Route: ['DUS', 'DSAJSF', 'GKRSLASLB', 'GUD', 'DUS'], Total Distance: 283.81, Total Demand: 97.75, Duration sailing: 40.54, Duration lossing: 19.4\n",
      "Shortest Route: ['DUS', 'DSAJSF', 'GKRSLASLB', 'TEB', 'DUS'], Total Distance: 280.37, Total Demand: 93.75, Duration sailing: 40.05, Duration lossing: 18.6\n",
      "Shortest Route: ['DUS', 'DSAJSF', 'GUD', 'TEB', 'DUS'], Total Distance: 282.15, Total Demand: 93.75, Duration sailing: 40.31, Duration lossing: 18.6\n",
      "Shortest Route: ['DUS', 'GKRSLASLB', 'GUD', 'TEB', 'DUS'], Total Distance: 308.32, Total Demand: 50.0, Duration sailing: 44.05, Duration lossing: 9.92\n",
      "Shortest Route: ['DUS', 'DRA', 'GKRSLASLB', 'GUD', 'TEB', 'DUS'], Total Distance: 321.11, Total Demand: 64.0, Duration sailing: 45.87, Duration lossing: 12.7\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "shortest_routes_dict = {}\n",
    "\n",
    "def generate_routes(demand, distances):\n",
    "    cargo_capacity = cargo_capacity_psv\n",
    "    max_platforms = max_platforms_in_one_voyage + 2\n",
    "\n",
    "    def dp(platform, cargo_remaining, route, visited):\n",
    "        if cargo_remaining < 0:\n",
    "            return\n",
    "        if len(route) > max_platforms:\n",
    "            return\n",
    "        if platform == 'DUS' and len(route) > 2:\n",
    "            total_demand = sum(platforms_demand[p] for p in route[1:-1])\n",
    "            if total_demand <= cargo_capacity:\n",
    "                key = tuple(sorted(set(route)))\n",
    "                total_distance = sum(distances.loc[route[i], route[i+1]] for i in range(len(route)-1))\n",
    "                if key not in shortest_routes_dict or total_distance < shortest_routes_dict[key][1]:\n",
    "                    duration_sailing = round((total_distance / psv_speed), 2)\n",
    "                    duration_lossing = round(((total_demand * 1.389) / psv_speed), 2)\n",
    "                    duration_sailing = round(duration_sailing, 2)\n",
    "                    duration_lossing = round(duration_lossing, 2)\n",
    "                    shortest_routes_dict[key] = (route, total_distance, total_demand, duration_sailing, duration_lossing)\n",
    "            return\n",
    "\n",
    "        # Check if the current route is dominated\n",
    "        current_distance = sum(distances.loc[route[i], route[i+1]] for i in range(len(route)-1))\n",
    "        current_demand = sum(platforms_demand[p] for p in route[1:-1])\n",
    "        \n",
    "        # Check for dominance in existing routes\n",
    "        for key, (existing_route, existing_distance, existing_demand, _, _) in shortest_routes_dict.items():\n",
    "            if set(existing_route[1:-1]) == set(route[1:-1]) and existing_demand >= current_demand and existing_distance <= current_distance:\n",
    "                return\n",
    "        \n",
    "        # Check for dominance in subsequent routes starting with the same platforms\n",
    "        for existing_route in dominated_routes:\n",
    "            if set(existing_route[1:-1]) == set(route[1:-1]) and existing_demand >= current_demand and existing_distance <= current_distance:\n",
    "                return\n",
    "\n",
    "        for next_platform in platforms_demand.keys():\n",
    "            if next_platform != platform and next_platform not in visited:\n",
    "                try:\n",
    "                    distance_to_next = distances.loc[platform, next_platform]\n",
    "                    new_cargo_remaining = cargo_remaining - platforms_demand[next_platform]\n",
    "                    dp(next_platform, new_cargo_remaining, route + [next_platform], visited.union({next_platform}))\n",
    "                except KeyError:\n",
    "                    print(\"KeyError occurred for platform:\", next_platform)\n",
    "                    continue\n",
    "\n",
    "    for r in range(3, min(len(platforms_demand) + 3, max_platforms + 3)):\n",
    "        for route_combination in combinations(platforms_demand.keys(), r - 2):\n",
    "            route = ['DUS'] + list(route_combination) + ['DUS']\n",
    "            dp('DUS', cargo_capacity, route, {'DUS'})\n",
    "\n",
    "            # Add the current route to the dominated routes set\n",
    "            dominated_routes.add(tuple(route))\n",
    "\n",
    "    return shortest_routes_dict\n",
    "\n",
    "# Keep track of dominated routes to skip future routes starting with them\n",
    "dominated_routes = set()\n",
    "shortest_routes_dict = generate_routes(demand, distances)\n",
    "\n",
    "for route, distance, demand, duration_sailing, duration_lossing in shortest_routes_dict.values():\n",
    "    print(f\"Shortest Route: {route}, Total Distance: {round(distance,2)}, Total Demand: {demand}, Duration sailing: {duration_sailing}, Duration lossing: {duration_lossing}\")\n",
    "\n",
    "print(len(shortest_routes_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saves the shortest routes left to csv files in the generated_datafiles folder. In total 858 routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_only = [route for route, _, _, _, _ in shortest_routes_dict.values()]\n",
    "distances_only = [distance for _, distance, _, _, _ in shortest_routes_dict.values()]\n",
    "demand_only = [demand for _, _, demand, _, _ in shortest_routes_dict.values()]\n",
    "duration_sailing = [duration_sailing for _, _, _, duration_sailing, _ in shortest_routes_dict.values()]\n",
    "duration_lossing = [duration_lossing for _, _, _, _, duration_lossing in shortest_routes_dict.values()]\n",
    "\n",
    "df_distances = pd.DataFrame({'Distance': distances_only})\n",
    "df_demand = pd.DataFrame({'Demand': demand_only})\n",
    "df_duration_sailing = pd.DataFrame({'Duration (hours)': duration_sailing})\n",
    "df_duration_lossing = pd.DataFrame({'Duration (hours)': duration_lossing})\n",
    "\n",
    "df_distances.to_csv('generated_datafiles_allroutes/distances.csv', index=False)\n",
    "df_demand.to_csv('generated_datafiles_allroutes/demand.csv', index=False)\n",
    "df_duration_sailing.to_csv('generated_datafiles_allroutes/duration_sailing.csv', index=False)\n",
    "df_duration_lossing.to_csv('generated_datafiles_allroutes/duration_lossing.csv', index=False)\n",
    "route_file = \"generated_datafiles_allroutes/routes.csv\"\n",
    "\n",
    "\n",
    "def write_to_csv(filename, data):\n",
    "    with open(filename, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(data)\n",
    "\n",
    "write_to_csv(route_file, routes_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the reduced set of routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport csv\\n\\ndef contains_required_routes(route, required_routes):\\n    return all(required_route in route for required_route in required_routes)\\n\\ndef main():\\n    hda_additional_routes1 = [\"HDA\", \"SLB\"]\\n    hda_additional_routes2 = [\"HDA\", \"SLA\"]\\n    hda_additional_routes3 = [\"HDA\", \"DRA\"]\\n    hda_additional_routes4 = [\"HDA\", \"TEB\"]\\n\\n    dra_additional_routes1 = [\"DRA\", \"DAB\"]\\n    dra_additional_routes2 = [\"DRA\", \"GRA\"]\\n\\n    gkr_additional_routes1 = [\"GKR\", \"HDA\"]\\n\\n    teb_additional_routes1 = [\"TEB\", \"DAB\"]\\n    teb_additional_routes2 = [\"TEB\", \"GRA\"]\\n\\n    sla_additional_routes1 = [\"SLA\", \"DAB\"]\\n    sla_additional_routes2 = [\"SLA\", \"GRA\"]\\n\\n    slb_additional_routes1 = [\"SLB\", \"DAB\"]\\n    slb_additional_routes2 = [\"SLB\", \"GRA\"]\\n\\n    routes_with_hda_slb = []\\n    routes_with_hda_sla = []\\n    routes_with_hda_dra = []\\n    routes_with_hda_teb = []\\n\\n    routes_with_dra_dab = []\\n    routes_with_dra_gra = []\\n    routes_with_gkr_hda = []\\n    routes_with_teb_dab = []\\n\\n    routes_with_teb_gra = []\\n    routes_with_sla_dab = []\\n    routes_with_sla_gra = []\\n    routes_with_slb_dab = []\\n    routes_with_slb_gra = []\\n\\n    with open(\\'generated_datafiles_allroutes/routes.csv\\', \\'r\\') as file:\\n        csv_reader = csv.reader(file)\\n        for row_number, row in enumerate(csv_reader, start=1):\\n            if contains_required_routes(row, hda_additional_routes1):\\n                routes_with_hda_slb.append(row_number)\\n            if contains_required_routes(row, hda_additional_routes2):\\n                routes_with_hda_sla.append(row_number)\\n            if contains_required_routes(row, hda_additional_routes3):\\n                routes_with_hda_dra.append(row_number)\\n            if contains_required_routes(row, hda_additional_routes4):\\n                routes_with_hda_teb.append(row_number)\\n\\n            if contains_required_routes(row, dra_additional_routes1):\\n                routes_with_dra_dab.append(row_number)\\n            if contains_required_routes(row, dra_additional_routes2):\\n                routes_with_dra_gra.append(row_number)\\n\\n            if contains_required_routes(row, gkr_additional_routes1):\\n                routes_with_gkr_hda.append(row_number)\\n\\n            if contains_required_routes(row, teb_additional_routes1):\\n                routes_with_teb_dab.append(row_number)\\n            if contains_required_routes(row, teb_additional_routes2):\\n                routes_with_teb_gra.append(row_number)\\n            if contains_required_routes(row, sla_additional_routes1):\\n                routes_with_sla_dab.append(row_number)\\n            if contains_required_routes(row, sla_additional_routes2):\\n                routes_with_sla_gra.append(row_number)\\n            if contains_required_routes(row, slb_additional_routes1):\\n                routes_with_slb_dab.append(row_number)\\n            if contains_required_routes(row, slb_additional_routes2):\\n                routes_with_slb_gra.append(row_number)\\n\\n    # Finding rows where all combinations occur\\n    # Combine all lists into one\\n    all_routes = (\\n        routes_with_hda_slb + \\n        routes_with_hda_sla +\\n        routes_with_hda_dra +\\n        routes_with_hda_teb +\\n        routes_with_dra_dab +\\n        routes_with_dra_gra +\\n        routes_with_gkr_hda +\\n        routes_with_teb_dab +\\n        routes_with_teb_gra +\\n        routes_with_sla_dab +\\n        routes_with_sla_gra +\\n        routes_with_slb_dab +\\n        routes_with_slb_gra\\n    )\\n    # Convert the combined list into a set to remove duplicates\\n    unique_routes = set(all_routes)\\n\\n    # Convert the set back into a list if needed\\n    unique_routes_list = list(unique_routes)\\n    print((sorted(unique_routes_list)))\\n    print(len(unique_routes_list))\\n\\n    def filter_routes(input_file, output_file, exclude_indices):\\n        with open(input_file, \\'r\\', newline=\\'\\') as f_in,             open(output_file, \\'w\\', newline=\\'\\') as f_out:\\n            reader = csv.reader(f_in)\\n            writer = csv.writer(f_out)\\n\\n            for i, row in enumerate(reader):\\n                if i + 1 not in exclude_indices:  # Adjusting for 1-based indexing\\n                    writer.writerow(row)\\n\\n    def filter_otherfiles(input_file, output_file, exclude_indices):\\n        with open(input_file, \\'r\\', newline=\\'\\') as f_in,             open(output_file, \\'w\\', newline=\\'\\') as f_out:\\n            reader = csv.reader(f_in)\\n            writer = csv.writer(f_out)\\n\\n            for i, row in enumerate(reader):\\n                if i not in exclude_indices:  \\n                    writer.writerow(row)\\n\\n    # Example usage\\n    input_file = \\'generated_datafiles_allroutes/routes.csv\\'\\n    output_file = \\'generated_datafiles_reducedroutes2/routes.csv\\'\\n\\n    input_file2 = \\'generated_datafiles_allroutes/demand.csv\\'\\n    output_file2 = \\'generated_datafiles_reducedroutes2/demand.csv\\'\\n\\n    input_file3 = \\'generated_datafiles_allroutes/distances.csv\\'\\n    output_file3 = \\'generated_datafiles_reducedroutes2/distances.csv\\'\\n\\n    input_file4 = \\'generated_datafiles_allroutes/duration_lossing.csv\\'\\n    output_file4 = \\'generated_datafiles_reducedroutes2/duration_lossing.csv\\'\\n\\n    input_file5 = \\'generated_datafiles_allroutes/duration_sailing.csv\\'\\n    output_file5 = \\'generated_datafiles_reducedroutes2/duration_sailing.csv\\'\\n\\n    filter_routes(input_file, output_file, unique_routes_list)\\n    filter_otherfiles(input_file2, output_file2, unique_routes_list)\\n    filter_otherfiles(input_file3, output_file3, unique_routes_list)\\n    filter_otherfiles(input_file4, output_file4, unique_routes_list)\\n    filter_otherfiles(input_file5, output_file5, unique_routes_list)\\n\\nif __name__ == \"__main__\":\\n    main()\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import csv\n",
    "\n",
    "def contains_required_routes(route, required_routes):\n",
    "    return all(required_route in route for required_route in required_routes)\n",
    "\n",
    "def main():\n",
    "    hda_additional_routes1 = [\"HDA\", \"SLB\"]\n",
    "    hda_additional_routes2 = [\"HDA\", \"SLA\"]\n",
    "    hda_additional_routes3 = [\"HDA\", \"DRA\"]\n",
    "    hda_additional_routes4 = [\"HDA\", \"TEB\"]\n",
    "\n",
    "    dra_additional_routes1 = [\"DRA\", \"DAB\"]\n",
    "    dra_additional_routes2 = [\"DRA\", \"GRA\"]\n",
    "\n",
    "    gkr_additional_routes1 = [\"GKR\", \"HDA\"]\n",
    "\n",
    "    teb_additional_routes1 = [\"TEB\", \"DAB\"]\n",
    "    teb_additional_routes2 = [\"TEB\", \"GRA\"]\n",
    "\n",
    "    sla_additional_routes1 = [\"SLA\", \"DAB\"]\n",
    "    sla_additional_routes2 = [\"SLA\", \"GRA\"]\n",
    "\n",
    "    slb_additional_routes1 = [\"SLB\", \"DAB\"]\n",
    "    slb_additional_routes2 = [\"SLB\", \"GRA\"]\n",
    "\n",
    "    routes_with_hda_slb = []\n",
    "    routes_with_hda_sla = []\n",
    "    routes_with_hda_dra = []\n",
    "    routes_with_hda_teb = []\n",
    "\n",
    "    routes_with_dra_dab = []\n",
    "    routes_with_dra_gra = []\n",
    "    routes_with_gkr_hda = []\n",
    "    routes_with_teb_dab = []\n",
    "\n",
    "    routes_with_teb_gra = []\n",
    "    routes_with_sla_dab = []\n",
    "    routes_with_sla_gra = []\n",
    "    routes_with_slb_dab = []\n",
    "    routes_with_slb_gra = []\n",
    "\n",
    "    with open('generated_datafiles_allroutes/routes.csv', 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for row_number, row in enumerate(csv_reader, start=1):\n",
    "            if contains_required_routes(row, hda_additional_routes1):\n",
    "                routes_with_hda_slb.append(row_number)\n",
    "            if contains_required_routes(row, hda_additional_routes2):\n",
    "                routes_with_hda_sla.append(row_number)\n",
    "            if contains_required_routes(row, hda_additional_routes3):\n",
    "                routes_with_hda_dra.append(row_number)\n",
    "            if contains_required_routes(row, hda_additional_routes4):\n",
    "                routes_with_hda_teb.append(row_number)\n",
    "\n",
    "            if contains_required_routes(row, dra_additional_routes1):\n",
    "                routes_with_dra_dab.append(row_number)\n",
    "            if contains_required_routes(row, dra_additional_routes2):\n",
    "                routes_with_dra_gra.append(row_number)\n",
    "\n",
    "            if contains_required_routes(row, gkr_additional_routes1):\n",
    "                routes_with_gkr_hda.append(row_number)\n",
    "\n",
    "            if contains_required_routes(row, teb_additional_routes1):\n",
    "                routes_with_teb_dab.append(row_number)\n",
    "            if contains_required_routes(row, teb_additional_routes2):\n",
    "                routes_with_teb_gra.append(row_number)\n",
    "            if contains_required_routes(row, sla_additional_routes1):\n",
    "                routes_with_sla_dab.append(row_number)\n",
    "            if contains_required_routes(row, sla_additional_routes2):\n",
    "                routes_with_sla_gra.append(row_number)\n",
    "            if contains_required_routes(row, slb_additional_routes1):\n",
    "                routes_with_slb_dab.append(row_number)\n",
    "            if contains_required_routes(row, slb_additional_routes2):\n",
    "                routes_with_slb_gra.append(row_number)\n",
    "\n",
    "    # Finding rows where all combinations occur\n",
    "    # Combine all lists into one\n",
    "    all_routes = (\n",
    "        routes_with_hda_slb + \n",
    "        routes_with_hda_sla +\n",
    "        routes_with_hda_dra +\n",
    "        routes_with_hda_teb +\n",
    "        routes_with_dra_dab +\n",
    "        routes_with_dra_gra +\n",
    "        routes_with_gkr_hda +\n",
    "        routes_with_teb_dab +\n",
    "        routes_with_teb_gra +\n",
    "        routes_with_sla_dab +\n",
    "        routes_with_sla_gra +\n",
    "        routes_with_slb_dab +\n",
    "        routes_with_slb_gra\n",
    "    )\n",
    "    # Convert the combined list into a set to remove duplicates\n",
    "    unique_routes = set(all_routes)\n",
    "\n",
    "    # Convert the set back into a list if needed\n",
    "    unique_routes_list = list(unique_routes)\n",
    "    print((sorted(unique_routes_list)))\n",
    "    print(len(unique_routes_list))\n",
    "\n",
    "    def filter_routes(input_file, output_file, exclude_indices):\n",
    "        with open(input_file, 'r', newline='') as f_in, \\\n",
    "            open(output_file, 'w', newline='') as f_out:\n",
    "            reader = csv.reader(f_in)\n",
    "            writer = csv.writer(f_out)\n",
    "\n",
    "            for i, row in enumerate(reader):\n",
    "                if i + 1 not in exclude_indices:  # Adjusting for 1-based indexing\n",
    "                    writer.writerow(row)\n",
    "\n",
    "    def filter_otherfiles(input_file, output_file, exclude_indices):\n",
    "        with open(input_file, 'r', newline='') as f_in, \\\n",
    "            open(output_file, 'w', newline='') as f_out:\n",
    "            reader = csv.reader(f_in)\n",
    "            writer = csv.writer(f_out)\n",
    "\n",
    "            for i, row in enumerate(reader):\n",
    "                if i not in exclude_indices:  \n",
    "                    writer.writerow(row)\n",
    "\n",
    "    # Example usage\n",
    "    input_file = 'generated_datafiles_allroutes/routes.csv'\n",
    "    output_file = 'generated_datafiles_reducedroutes2/routes.csv'\n",
    "\n",
    "    input_file2 = 'generated_datafiles_allroutes/demand.csv'\n",
    "    output_file2 = 'generated_datafiles_reducedroutes2/demand.csv'\n",
    "\n",
    "    input_file3 = 'generated_datafiles_allroutes/distances.csv'\n",
    "    output_file3 = 'generated_datafiles_reducedroutes2/distances.csv'\n",
    "\n",
    "    input_file4 = 'generated_datafiles_allroutes/duration_lossing.csv'\n",
    "    output_file4 = 'generated_datafiles_reducedroutes2/duration_lossing.csv'\n",
    "\n",
    "    input_file5 = 'generated_datafiles_allroutes/duration_sailing.csv'\n",
    "    output_file5 = 'generated_datafiles_reducedroutes2/duration_sailing.csv'\n",
    "\n",
    "    filter_routes(input_file, output_file, unique_routes_list)\n",
    "    filter_otherfiles(input_file2, output_file2, unique_routes_list)\n",
    "    filter_otherfiles(input_file3, output_file3, unique_routes_list)\n",
    "    filter_otherfiles(input_file4, output_file4, unique_routes_list)\n",
    "    filter_otherfiles(input_file5, output_file5, unique_routes_list)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
